\begin{frame}
	\vspace{2cm}
	\begin{center}
		{\Huge\textbf{\textcolor{copenhagenred}{Pseudo-marginal MCMC}}}
		\vspace{1cm}

		\rule{4cm}{3pt}
		\vspace{2cm}
	\end{center}
\end{frame}

\begin{frame}{The Challenge: Intractable Marginals}
	\vspace{0.5cm}

	\begin{columns}
		\column{0.5\textwidth}
		\textbf{The Problem:}
		\begin{itemize}
			\item Target: $\pi(x) = \int f(x,u) du$
			\item $f(x,u)$ is known (complete data)
			\item Integral is \textcolor{copenhagenred}{intractable}
			\item Standard MCMC requires exact $\pi(x)$
		\end{itemize}

		\vspace{0.5cm}
		\textbf{Key Insight:} We can \textcolor{copenhagenred}{estimate} $\pi(x)$ unbiasedly!

		\column{0.5\textwidth}
		\begin{tikzpicture}[scale=0.8]
			% Draw the 3D-like space
			\draw[fill=copenhagenred!20] (0,0) rectangle (4,3);
			\node at (2,2.5) {$f(x,u)$};
			\node at (2,1.5) {(known)};

			% Draw marginal
			\draw[->, thick, copenhagenred] (4.5,1.5) -- (5.5,1.5);
			\draw[fill=copenhagenred!40] (6,0.5) rectangle (6.3,2.5);
			\node at (6.15,1.5) [rotate=90] {$\pi(x)$};
			\node at (6.15,-0.2) {(unknown)};

			% Integration symbol
			\node at (5,2.2) {$\int du$};
		\end{tikzpicture}

	\end{columns}
\end{frame}

% Slide 2: The Solution
\begin{frame}{The Pseudo-marginal Solution}

	\begin{columns}

		\column{0.5\textwidth}
		\textbf{Key Prerequisites}

		\vspace{0.15cm}
		For pseudo-marginal MCMC to be applicable, we need:
		\begin{enumerate}
			\item Ability to \textbf{evaluate} $f(x,u)$ pointwise for any $(x,u)$
			\item Ability to \textbf{sample} from an importance distribution $q_x(\cdot)$ over the $u$-space
			\item The importance distribution must have appropriate support: $q_x(u) > 0$ whenever $f(x,u) > 0$
		\end{enumerate}

		\column{0.5\textwidth}
		\textbf{Importance Sampling Estimator:}
		\begin{equation*}
			\hat{\pi}(x) = \frac{1}{N} \sum_{i=1}^{N} \frac{f(x,U_i)}{q_x(U_i)}, \quad U_i \sim q_x(\cdot)
		\end{equation*}

		\vspace{0.2cm}
		\textbf{Key Property:} $\mathbb{E}[\hat{\pi}(x)] = \pi(x)$ (unbiased!)

		\vspace{0.2cm}
		\textbf{The Magic:} Replace $\pi$ with $\hat{\pi}$ in MH ratio!
		\begin{equation*}
			\alpha = \min\left\{1, \frac{\hat{\pi}(y)q(y,x)}{\hat{\pi}(x)q(x,y)}\right\}
		\end{equation*}
		\vspace{0.2cm}
		\textcolor{copenhagenred}{\textbf{Result:}} Still targets correct $\pi(x)$!

	\end{columns}
\end{frame}

\begin{frame}{Why It Works: Extended Target}
	One can think of estimator (the “pseudo-marginal”) as the product of the true target and a random variable:
	\begin{equation*}
		\hat{\pi}(x) = \pi(x) Z_x
	\end{equation*}
	where $Z_x$ satifies:
	\begin{enumerate}
		\item is non-negative: $Z_x \geq 0$,
		\item has density $g_x(\cdot)$: $\int_0^{\infty} g_x(z)dz = 1$
		\item has expectation 1: $\mathbb{E}[Z_x] = \int_0^{\infty} z g_x(z) dz = 1$.
	\end{enumerate}
\end{frame}

\begin{frame}{Why It Works: Extended Target}
	\textbf{Extended Target Construction:}
	\begin{equation*}
		\bar{\pi}(x,z) = \pi(x) \cdot z \cdot g_x(z)
	\end{equation*}

	where $g_x(z)$ is the density of $Z_x$

	\vspace{0.2cm}
	\textbf{Key Property:}
	\begin{equation*}
		\int \bar{\pi}(x,z) dz = \pi(x)
	\end{equation*}

	Now apply Metropolis–Hastings with proposal
	\begin{equation*}
		\bar{q}((x, z), (y, w)) := q(x, y) \cdot g_y(w).
	\end{equation*}

	\vspace{0.2cm}
	\textbf{Intuition:}
	\begin{itemize}
		\item Run exact MCMC on $(x,z)$ space
		\item Marginal in $x$ gives correct target
		\item $z$ represents the "noise" in estimates
	\end{itemize}
\end{frame}

\begin{frame}{Equivalence to MH on Extended Space}
	\begin{theorem}[Equivalence]
		Metropolis-Hastings on the extended target $\bar{\pi}$ with proposal $\bar{q}$ is equivalent to the pseudo-marginal algorithm using estimates $\hat{\pi}$.
	\end{theorem}

	Proof Sketch:
	The MH acceptance ratio on the extended space is:
	\begin{align*}
		\alpha_{ext} & = \min\left\{1, \frac{\bar{\pi}(y,w)\bar{q}((y,w),(x,z))}{\bar{\pi}(x,z)\bar{q}((x,z),(y,w))}\right\}                                       \\
		             & = \min\left\{1, \frac{\pi(y) \cdot w \cdot g_y(w) \cdot q(y,x) \cdot g_x(z)}{\pi(x) \cdot z \cdot g_x(z) \cdot q(x,y) \cdot g_y(w)}\right\} \\
		             & = \min\left\{1, \frac{\pi(y) \cdot w \cdot q(y,x)}{\pi(x) \cdot z \cdot q(x,y)}\right\}
		= \min\left\{1, \frac{\hat{\pi}(y)q(y,x)}{\hat{\pi}(x)q(x,y)}\right\} = \alpha_{pm}
	\end{align*}
	In the last step, we used $\hat{\pi}(x) = \pi(x) z$ and $\hat{\pi}(y) = \pi(y) w$,
	which is exactly the pseudo-marginal acceptance probability.
\end{frame}

\begin{frame}{Pseudo-marginal MCMC Algorithm}
	\begin{columns}
		\column{0.5\textwidth}

		\begin{block}{Given $(X^{(t-1)}, \hat{\pi}^{(t-1)})$:}
			\begin{enumerate}
				\item \textbf{Propose:} $Y \sim q(X^{(t-1)}, \cdot)$
				\item \textbf{Estimate:}
				      \begin{itemize}
					      \item Sample $U_i \sim q_Y(\cdot)$
					      \item $\hat{\pi}(Y) = \frac{1}{N}\sum_{i} \frac{f(Y,U_i)}{q_Y(U_i)}$
				      \end{itemize}
				\item \textbf{Accept with probability:}
				      $$\alpha = \min\left\{1, \frac{\hat{\pi}(Y)q(Y,X^{(t-1)})}{\hat{\pi}^{(t-1)}q(X^{(t-1)},Y)}\right\}$$
				\item \textbf{Update:}
				      \begin{itemize}
					      \item If accept: $(X^{(t)}, \hat{\pi}^{(t)}) = (Y, \hat{\pi}(Y))$
					      \item Else: $(X^{(t)}, \hat{\pi}^{(t)}) = (X^{(t-1)}, \hat{\pi}^{(t-1)})$
				      \end{itemize}
			\end{enumerate}
		\end{block}

		\column{0.5\textwidth}
		\textcolor{copenhagenred}{\textbf{Critical Points:}}
		\begin{itemize}
			\item Store estimates with states! In the next iteration, use the stored $\hat{\pi}(X^{(t-1)})$.
			\item Fresh randomness for each proposal. Every time you propose a new state Y, you must generate a completely new, independent estimate $\hat{\pi}(Y)$ using fresh random samples.
			\item Works with \textit{any} MH proposal $q$
		\end{itemize}

	\end{columns}
\end{frame}


\begin{frame}
$$\hat{\omega}(x) = \frac{1}{N} \sum_{i=1}^{N} \frac{f(x, U_i)}{q_x(U_i)}, \quad U_i \overset{\text{i.i.d.}}{\sim} q_x(\cdot)$$



% Let's verify E[ˆω(x)] = ω(x):
$$\mathbb{E}[\hat{\omega}(x)] = \mathbb{E}\left[\frac{1}{N} \sum_{i=1}^{N} \frac{f(x, U_i)}{q_x(U_i)}\right]$$


$$= \frac{1}{N} \sum_{i=1}^{N} \mathbb{E}\left[\frac{f(x, U_i)}{q_x(U_i)}\right]$$

% For each term (since U_i ~ q_x):
$$\mathbb{E}\left[\frac{f(x, U_i)}{q_x(U_i)}\right] = \int \frac{f(x, u)}{q_x(u)} \cdot q_x(u) , du = \int f(x, u) , du$$
\end{frame}
